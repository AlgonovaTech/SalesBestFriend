# ğŸ“š SalesBestFriend - ĞŸĞ¾Ğ»Ğ½Ğ°Ñ ĞŸÑ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ²Ğ¾-Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ

**Ğ’ĞµÑ€ÑĞ¸Ñ:** 2.0  
**Ğ”Ğ°Ñ‚Ğ°:** 24 Ğ½Ğ¾ÑĞ±Ñ€Ñ 2025  
**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** Production Ready

---

## ğŸ“‹ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [ĞĞ±Ğ·Ğ¾Ñ€ ĞŸÑ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°](#1-Ğ¾Ğ±Ğ·Ğ¾Ñ€-Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°)
2. [ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ñ‹](#2-Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°-ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹)
3. [Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¡Ñ‚ĞµĞº](#3-Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹-ÑÑ‚ĞµĞº)
4. [Backend ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹](#4-backend-ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹)
5. [Frontend ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹](#5-frontend-ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹)
6. [ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¸ Ğ”Ğ°Ğ½Ğ½Ñ‹Ñ…](#6-Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
7. [AI/LLM Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ](#7-aillm-Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ)
8. [Deployment](#8-deployment)
9. [ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ](#9-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ)
10. [Security & Permissions](#10-security--permissions)

---

## 1. ĞĞ±Ğ·Ğ¾Ñ€ ĞŸÑ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°

### 1.1 Ğ§Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ?

**SalesBestFriend** â€” ÑÑ‚Ğ¾ AI-powered Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ¾Ğ², Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´ÑÑ‰Ğ¸Ñ… trial class (Ğ¿Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ ÑƒÑ€Ğ¾ĞºĞ¸) Ğ¿Ğ¾ Zoom/Google Meet. Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸, Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ğ½Ğ° **Ğ¸Ğ½Ğ´Ğ¾Ğ½ĞµĞ·Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ** Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑ:

- âœ… **Ğ§ĞµĞºĞ»Ğ¸ÑÑ‚ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°** â€” 7 ÑÑ‚Ğ°Ğ´Ğ¸Ğ¹ Ğ·Ğ²Ğ¾Ğ½ĞºĞ° Ñ 25+ Ğ¿ÑƒĞ½ĞºÑ‚Ğ°Ğ¼Ğ¸
- ğŸ¯ **Ğ¢Ğ°Ğ¹Ğ¼Ğ¸Ğ½Ğ³ ÑÑ‚Ğ°Ğ´Ğ¸Ğ¹** â€” ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚, ĞºĞ¾Ğ³Ğ´Ğ° Ğ²Ñ‹ Ğ¾Ñ‚ÑÑ‚Ğ°ĞµÑ‚Ğµ Ğ¾Ñ‚ Ğ¿Ğ»Ğ°Ğ½Ğ°
- ğŸ‘¤ **Client Card** â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğµ
- ğŸ¤ **Real-time Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ** â€” Whisper Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 3 ÑĞµĞºÑƒĞ½Ğ´Ñ‹
- ğŸ¤– **AI Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·** â€” Gemini 2.5 Flash Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ

### 1.2 ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Use Cases

1. **Trial Class Ğ´Ğ»Ñ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½-ÑˆĞºĞ¾Ğ»Ñ‹ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ** (Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹)
   - Ğ Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ñ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ĞµĞ¼ + Ñ€ĞµĞ±ĞµĞ½ĞºĞ¾Ğ¼
   - Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹
   - Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹
   - Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ½Ğ° Ğ¿Ğ¾ĞºÑƒĞ¿ĞºÑƒ Ğ¿Ğ°ĞºĞµÑ‚Ğ°

2. **YouTube Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·** â€” Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ·Ğ²Ğ¾Ğ½ĞºĞ° Ğ´Ğ»Ñ post-mortem Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°

3. **Debug mode** â€” Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ LLM

---

## 2. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ñ‹

### 2.1 High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VERCEL (Frontend)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  React App (TypeScript + Vite)                         â”‚ â”‚
â”‚  â”‚  - UI Components                                       â”‚ â”‚
â”‚  â”‚  - WebSocket Clients                                   â”‚ â”‚
â”‚  â”‚  - MediaRecorder (Audio Capture)                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            WebSocket â”‚ (wss://)
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAILWAY (Backend)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI Server (Python 3.11)                          â”‚  â”‚
â”‚  â”‚  - WebSocket Handlers (/ingest, /coach)               â”‚  â”‚
â”‚  â”‚  - Real-time Transcriber (Faster-Whisper)             â”‚  â”‚
â”‚  â”‚  - Trial Class Analyzer (LLM Integration)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         HTTPS POST  â”‚
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  OpenRouter API                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Gemini 2.5 Flash (google/gemini-2.5-flash-preview)   â”‚  â”‚
â”‚  â”‚  - Checklist item completion detection                 â”‚  â”‚
â”‚  â”‚  - Client card field extraction                        â”‚  â”‚
â”‚  â”‚  - Evidence validation                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Communication Patterns

#### 2.2.1 Audio Ingestion Flow

```
Browser (MediaRecorder)
    â”‚
    â”‚ Binary WebM chunks (every 3s)
    â–¼
WebSocket /ingest
    â”‚
    â–¼
AudioBuffer (in-memory queue)
    â”‚
    â”‚ Trigger on buffer size or timeout
    â–¼
Faster-Whisper (local transcription)
    â”‚
    â”‚ Indonesian text
    â–¼
accumulated_transcript (global state)
```

#### 2.2.2 Analysis & Update Flow

```
Backend Timer (every 5s)
    â”‚
    â–¼
Trial Class Analyzer
    â”‚
    â”œâ”€> LLM Call #1: Check incomplete checklist items
    â”‚   â””â”€> For each item: check_checklist_item()
    â”‚       â””â”€> LLM validates evidence
    â”‚
    â”œâ”€> LLM Call #2: Extract client card fields
    â”‚   â””â”€> extract_client_card_fields()
    â”‚       â””â”€> LLM validates evidence
    â”‚
    â””â”€> Build coach update message
        â””â”€> Send via WebSocket /coach to all connected clients
```

#### 2.2.3 Frontend Update Flow

```
WebSocket /coach
    â”‚
    â”‚ JSON message
    â–¼
React State Update
    â”‚
    â”œâ”€> setStages(data.stages)           â†’ StageChecklist component
    â”œâ”€> setClientCard(data.clientCard)   â†’ ClientCard component
    â”œâ”€> setCallElapsed(...)               â†’ CallTimer component
    â””â”€> setDebugLogs(...)                 â†’ DebugLogPanel component
```

---

## 3. Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¡Ñ‚ĞµĞº

### 3.1 Backend

| Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|------------|--------|------------|
| **Python** | 3.11+ | Runtime |
| **FastAPI** | 0.109.0 | Web framework + WebSockets |
| **Uvicorn** | 0.27.0 | ASGI server |
| **Faster-Whisper** | 1.2.0 | Speech-to-text (Indonesian) |
| **CTranslate2** | 4.6.0 | Whisper inference engine |
| **Requests** | 2.31.0 | HTTP client Ğ´Ğ»Ñ OpenRouter |
| **Python-dotenv** | 1.0.0 | Environment configuration |
| **PyDub** | 0.25.1 | Audio processing |
| **yt-dlp** | 2025.10.22 | YouTube audio extraction |

### 3.2 Frontend

| Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ | Ğ’ĞµÑ€ÑĞ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|------------|--------|------------|
| **React** | 18.2.0 | UI framework |
| **TypeScript** | 5.3.3 | Type safety |
| **Vite** | 5.0.8 | Build tool + dev server |
| **CSS** | Native | Styling (no frameworks) |

### 3.3 External Services

| Ğ¡ĞµÑ€Ğ²Ğ¸Ñ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | ĞœĞ¾Ğ´ĞµĞ»ÑŒ |
|--------|------------|--------|
| **OpenRouter** | LLM API Gateway | Gemini 2.5 Flash |
| **Railway** | Backend hosting | Container deployment |
| **Vercel** | Frontend hosting | Edge deployment |

---

## 4. Backend ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹

### 4.1 Core Files

#### 4.1.1 `main_trial_class.py`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ entry point FastAPI Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸:**

1. **WebSocket `/ingest`** â€” Ğ¿Ñ€Ğ¸ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²
   ```python
   @app.websocket("/ingest")
   async def websocket_ingest(websocket: WebSocket):
       # Accepts binary audio chunks (WebM)
       # Buffers them in AudioBuffer
       # Triggers transcription on buffer threshold
   ```

2. **WebSocket `/coach`** â€” Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ UI
   ```python
   @app.websocket("/coach")
   async def websocket_coach(websocket: WebSocket):
       # Sends real-time updates:
       # - Call structure (stages, items)
       # - Client card data
       # - Timing status
       # - Debug logs
   ```

3. **Background Task: `analyze_conversation_loop()`**
   ```python
   async def analyze_conversation_loop():
       while True:
           await asyncio.sleep(5)  # Every 5 seconds
           # 1. Check incomplete checklist items
           # 2. Extract client card fields
           # 3. Broadcast updates to all /coach connections
   ```

4. **Transcription Handler: `handle_transcription()`**
   ```python
   def handle_transcription(text: str):
       global accumulated_transcript
       accumulated_transcript += text
       # Keep only last 1000 words for LLM context window
   ```

**Global State:**

```python
# WebSocket connections
coach_connections: Set[WebSocket] = set()

# Transcription state
accumulated_transcript: str = ""
transcription_language: str = "id"  # Indonesian
is_live_recording: bool = False

# Call structure
call_structure = get_default_call_structure()  # 7 stages
client_card_fields = get_default_client_card_fields()  # 11 fields

# Progress tracking
checklist_progress: Dict[str, bool] = {}
checklist_evidence: Dict[str, str] = {}
checklist_last_check: Dict[str, float] = {}

# Client data
client_card_data: Dict[str, Dict[str, str]] = {}

# Timing
call_start_time: Optional[float] = None
current_stage_id: str = ""
stage_start_time: Optional[float] = None
```

---

#### 4.1.2 `trial_class_analyzer.py`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** LLM-based Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°

**ĞšĞ»Ğ°ÑÑ:** `TrialClassAnalyzer`

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹:**

1. **`check_checklist_item()`**
   ```python
   def check_checklist_item(
       self,
       item_id: str,
       item_content: str,
       item_type: str,  # "discuss" or "say"
       conversation_text: str
   ) -> Tuple[bool, float, str, Dict]:
       """
       ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ Ğ»Ğ¸ Ğ¿ÑƒĞ½ĞºÑ‚ Ñ‡ĞµĞºĞ»Ğ¸ÑÑ‚Ğ°
       
       Returns:
           (completed, confidence, evidence, debug_info)
       """
       # 1. Build prompt based on item type
       # 2. Call LLM with strict validation instructions
       # 3. Parse JSON response
       # 4. Apply guards:
       #    - Guard 1: Confidence must be >= 0.8
       #    - Guard 2: Evidence must be >= 10 chars
       #    - Guard 3: Validate evidence with second LLM call
       # 5. Return result
   ```

2. **`_validate_evidence_relevance()`**
   ```python
   def _validate_evidence_relevance(
       self,
       item_content: str,
       evidence: str,
       reasoning: str,
       item_type: str
   ) -> bool:
       """
       Ğ’Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ LLM Ğ´Ğ»Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ evidence
       
       ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚:
       - Evidence Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸ĞµĞ¼ ("oke", "halo")
       - Evidence ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ²ÑĞ·Ğ°Ğ½Ğ° Ñ item_content
       - Evidence Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸Ñ‡Ğ½Ğ°
       """
       # Hard-coded filters
       invalid_phrases = ["oke", "ok", "baik", "ya", "halo", ...]
       introduction_patterns = ["nama saya", "saya adalah", ...]
       
       # Keyword-based semantic check
       keyword_checks = [
           {"triggers": ["age", "umur"], "required_in_evidence": ["umur", "tahun"]},
           ...
       ]
       
       # Final LLM validation
       response = self._call_llm(validation_prompt)
       return result.get("is_valid", False)
   ```

3. **`extract_client_card_fields()`**
   ```python
   def extract_client_card_fields(
       self,
       conversation_text: str,
       current_values: Dict[str, str]
   ) -> Dict[str, Dict[str, str]]:
       """
       Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ° Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°
       
       Returns:
           {field_id: {value, evidence, confidence, label}}
       """
       # 1. Build field descriptions with hints
       # 2. Call LLM with strict anti-hallucination rules
       # 3. Filter out fields with existing values
       # 4. Apply guards:
       #    - Guard 0: Reject placeholder values ("tidak disebutkan")
       #    - Guard 1: Value must be substantial (>5 chars)
       #    - Guard 2: Confidence must be >= 0.7
       #    - Guard 3: Evidence must exist (>10 chars)
       #    - Guard 4: Validate evidence with second LLM call
       # 5. Return updates
   ```

4. **`_call_llm()`**
   ```python
   def _call_llm(
       self,
       prompt: str,
       temperature: float = 0.5,
       max_tokens: int = 500
   ) -> str:
       """
       Ğ’Ñ‹Ğ·Ğ¾Ğ² OpenRouter API
       
       Model: google/gemini-2.5-flash-preview-09-2025
       Reason: Fastest, cheapest, good for Indonesian
       """
       response = requests.post(
           "https://openrouter.ai/api/v1/chat/completions",
           headers={"Authorization": f"Bearer {api_key}"},
           json={
               "model": self.model,
               "messages": [{"role": "user", "content": prompt}],
               "temperature": temperature,
               "max_tokens": max_tokens
           }
       )
       # Extract JSON from response (handles markdown wrapping)
   ```

**LLM Prompt Engineering:**

Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ **multi-layer validation** Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹:

1. **First LLM call**: Initial check Ñ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¸Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸ÑĞ¼Ğ¸
2. **Hard-coded filters**: Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ generic phrases ("oke", "baik")
3. **Semantic validation**: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ² Ğ² evidence
4. **Second LLM call**: Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ, Ñ‡Ñ‚Ğ¾ evidence Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ´Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ action

---

#### 4.1.3 `call_structure_config.py`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ·Ğ²Ğ¾Ğ½ĞºĞ°

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:**

```python
DEFAULT_CALL_STRUCTURE: List[CallStage] = [
    {
        "id": "stage_1_opening",
        "name": "Opening & Greeting",
        "startOffsetSeconds": 0,
        "durationSeconds": 120,  # 2 min
        "items": [
            {
                "id": "greet_client",
                "type": "say",  # "say" or "discuss"
                "content": "Greet the client warmly..."
            },
            ...
        ]
    },
    {
        "id": "stage_2_discovery",
        "name": "Understanding Needs",
        "startOffsetSeconds": 120,  # 2 min
        "durationSeconds": 300,  # 5 min
        "items": [...]
    },
    # ... 7 stages total
]
```

**Ğ¡Ñ‚Ğ°Ğ´Ğ¸Ğ¸ Ğ·Ğ²Ğ¾Ğ½ĞºĞ°:**

1. **Opening & Greeting** (0-2 min) â€” 3 items
2. **Understanding Needs** (2-7 min) â€” 5 items
3. **Trial Class Introduction** (7-10 min) â€” 3 items
4. **Conducting Trial Class** (10-30 min) â€” 5 items
5. **Trial Feedback & Discussion** (30-35 min) â€” 4 items
6. **Address Concerns** (35-40 min) â€” 4 items
7. **Closing & Next Steps** (40-45 min) â€” 5 items

**Total:** 29 checklist items

**Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸:**

```python
def get_stage_by_time(elapsed_seconds: int) -> str:
    """Fallback: Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ´Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸"""

def detect_stage_by_context(
    conversation_text: str,
    elapsed_seconds: int,
    analyzer
) -> str:
    """AI-based: Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ´Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ñƒ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°"""

def get_stage_timing_status(stage_id: str, elapsed_seconds: int) -> Dict:
    """
    Returns:
        {
            "status": "on_time" | "slightly_late" | "very_late",
            "message": "On track" | "2 min behind"
        }
    """
```

---

#### 4.1.4 `client_card_config.py`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ»ĞµĞ¹ Client Card

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:**

```python
DEFAULT_CLIENT_CARD_FIELDS: List[ClientCardField] = [
    # Child Information
    {"id": "child_name", "label": "Child's Name", ...},
    {"id": "child_interests", "label": "Child's Interests", ...},
    {"id": "child_experience", "label": "Prior Experience", ...},
    
    # Parent Information
    {"id": "parent_goal", "label": "Parent's Goal", ...},
    {"id": "learning_motivation", "label": "Why Learning Now", ...},
    
    # Needs & Pain Points
    {"id": "main_pain_point", "label": "Main Pain Point", ...},
    {"id": "desired_outcome", "label": "Desired Outcome", ...},
    
    # Concerns & Objections
    {"id": "objections", "label": "Objections Raised", ...},
    {"id": "budget_constraint", "label": "Budget Situation", ...},
    {"id": "schedule_constraint", "label": "Schedule Constraints", ...},
    
    # Additional
    {"id": "additional_notes", "label": "Additional Notes", ...}
]
```

**LLM Extraction Hints:**

```python
LLM_EXTRACTION_HINTS = {
    "child_name": "Extract child's name and age (e.g. 'Budi, 10 years old')",
    "child_interests": "Games (Minecraft, Roblox), activities, subjects",
    "parent_goal": "What parent wants: skills, career prep, creativity?",
    ...
}
```

---

#### 4.1.5 `utils/realtime_transcriber.py`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Whisper-based Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾

**ĞšĞ»ÑÑ‡ĞµĞ²Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ:**

```python
async def transcribe_audio_buffer(
    audio_buffer: AudioBuffer,
    model_size: str = "base",
    language: str = "id",
    callback=None
):
    """
    Transcribes audio from buffer using Faster-Whisper
    
    Args:
        audio_buffer: AudioBuffer instance with queued chunks
        model_size: "tiny", "base", "small", "medium", "large"
        language: Language code ("id" for Indonesian)
        callback: Function to call with transcribed text
    
    Process:
        1. Combine all audio chunks in buffer
        2. Write to temporary .webm file
        3. Load with Faster-Whisper
        4. Transcribe (VAD filter enabled)
        5. Call callback with text
        6. Clear buffer
    """
    model = WhisperModel(model_size, device="cpu", compute_type="int8")
    segments, info = model.transcribe(
        audio_file,
        language=language,
        vad_filter=True,  # Voice Activity Detection
        vad_parameters=dict(
            min_silence_duration_ms=500,
            speech_pad_ms=200
        )
    )
```

**ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Whisper:**

| Ğ Ğ°Ğ·Ğ¼ĞµÑ€ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ | Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ | Use Case |
|--------|-----------|----------|----------|----------|
| `tiny` | 39M | Fastest | Low | Quick tests |
| `base` | 74M | Fast | Good | **Production** âœ… |
| `small` | 244M | Medium | Better | High accuracy needed |
| `medium` | 769M | Slow | Best | Offline processing |

**Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:** `base` Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ±Ğ°Ğ»Ğ°Ğ½ÑĞ° ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸.

---

#### 4.1.6 `utils/audio_buffer.py`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Ğ‘ÑƒÑ„ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²

```python
class AudioBuffer:
    """In-memory buffer for audio chunks"""
    
    def __init__(self):
        self.chunks: List[bytes] = []
        self.lock = asyncio.Lock()
    
    async def append(self, chunk: bytes):
        """Add audio chunk to buffer"""
        async with self.lock:
            self.chunks.append(chunk)
    
    async def get_all_and_clear(self) -> List[bytes]:
        """Get all chunks and clear buffer"""
        async with self.lock:
            result = self.chunks.copy()
            self.chunks.clear()
            return result
    
    def size(self) -> int:
        """Get number of chunks in buffer"""
        return len(self.chunks)
```

---

### 4.2 API Endpoints

#### HTTP Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/` | Service info |
| `GET` | `/health` | Health check + connections count |
| `GET` | `/call-structure` | Get current call structure config |
| `POST` | `/call-structure` | Update call structure (for settings) |
| `GET` | `/client-card-fields` | Get client card field definitions |
| `POST` | `/reset` | Reset all state (new call) |
| `POST` | `/youtube-process` | Process YouTube video URL |

#### WebSocket Endpoints

| Path | Direction | Description |
|------|-----------|-------------|
| `/ingest` | Client â†’ Server | Audio chunks (binary WebM) |
| `/coach` | Server â†’ Client | Real-time updates (JSON) |

---

## 5. Frontend ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹

### 5.1 Core Files

#### 5.1.1 `App_TrialClass.tsx`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ

**State Management:**

```typescript
const [isRecording, setIsRecording] = useState(false)
const [status, setStatus] = useState<'idle' | 'connecting' | 'connected'>('idle')
const [callElapsed, setCallElapsed] = useState(0)  // seconds
const [stageElapsed, setStageElapsed] = useState(0)
const [currentStageId, setCurrentStageId] = useState<string>('')
const [stages, setStages] = useState<Stage[]>([])
const [clientCard, setClientCard] = useState<Record<string, string>>({})
const [debugLogs, setDebugLogs] = useState<DebugLogEntry[]>([])
const [selectedLanguage, setSelectedLanguage] = useState('id')
```

**WebSocket Connections:**

```typescript
// /coach WebSocket for receiving updates
const coachWs = new WebSocket(`${API_WS}/coach`)

coachWs.onmessage = (e) => {
    const data: CoachMessage = JSON.parse(e.data)
    setCallElapsed(data.callElapsedSeconds)
    setStages(data.stages)
    setClientCard(data.clientCard)
    setDebugLogs(data.debugLog || [])
}

// /ingest WebSocket for sending audio
const ingestWs = new WebSocket(`${API_WS}/ingest`)
```

**Audio Capture:**

```typescript
const startRecording = async () => {
    // Request tab audio capture
    const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: true  // âš ï¸ CRITICAL: Must enable audio
    })
    
    // Create MediaRecorder
    const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus',
        audioBitsPerSecond: 16000
    })
    
    // Send chunks to /ingest
    mediaRecorder.ondataavailable = (e) => {
        if (ingestWs.readyState === WebSocket.OPEN) {
            ingestWs.send(e.data)  // Binary send
        }
    }
    
    // Start with 3s chunks
    mediaRecorder.start(3000)
}
```

**Local Timer:**

```typescript
useEffect(() => {
    if (isRecording && callStartTimeRef.current) {
        timerIntervalRef.current = setInterval(() => {
            const elapsed = Math.floor((Date.now() - callStartTimeRef.current!) / 1000)
            setCallElapsed(elapsed)
        }, 1000)
    }
}, [isRecording])
```

---

#### 5.1.2 `components/StageChecklist.tsx`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ğ´Ğ¸Ğ¹ Ğ¸ Ñ‡ĞµĞºĞ»Ğ¸ÑÑ‚Ğ°

**Props:**

```typescript
interface Props {
    stages: Stage[]
    currentStageId: string
    callElapsed: number
}
```

**Rendering Logic:**

```typescript
<div className="stage-checklist">
    {stages.map(stage => (
        <div className={`stage ${stage.isCurrent ? 'current' : ''}`}>
            <div className="stage-header">
                <h3>{stage.name}</h3>
                <div className={`timing-badge ${stage.timingStatus}`}>
                    {stage.timingMessage}
                </div>
            </div>
            
            <div className="checklist-items">
                {stage.items.map(item => (
                    <div className={`item ${item.completed ? 'completed' : ''}`}>
                        <input 
                            type="checkbox" 
                            checked={item.completed}
                            disabled
                        />
                        <span className="item-content">
                            {item.content}
                        </span>
                        {item.evidence && (
                            <div className="evidence">
                                ğŸ’¬ {item.evidence}
                            </div>
                        )}
                    </div>
                ))}
            </div>
        </div>
    ))}
</div>
```

**Timing Status Colors:**

- `on_time` â†’ Green badge: "On track"
- `slightly_late` â†’ Yellow badge: "Slightly behind"
- `very_late` â†’ Red badge: "X min behind"
- `not_started` â†’ Gray badge: "Starts in X min"

---

#### 5.1.3 `components/ClientCard.tsx`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğµ

**Props:**

```typescript
interface Props {
    clientCard: Record<string, string>
}
```

**Layout:**

```typescript
<div className="client-card">
    <h2>ğŸ‘¤ Client Information</h2>
    
    <div className="field-group">
        <h3>Child Info</h3>
        {renderField("child_name")}
        {renderField("child_interests")}
        {renderField("child_experience")}
    </div>
    
    <div className="field-group">
        <h3>Parent Goals</h3>
        {renderField("parent_goal")}
        {renderField("learning_motivation")}
    </div>
    
    <div className="field-group">
        <h3>Pain Points</h3>
        {renderField("main_pain_point")}
        {renderField("desired_outcome")}
    </div>
    
    <div className="field-group">
        <h3>Concerns</h3>
        {renderField("objections")}
        {renderField("budget_constraint")}
        {renderField("schedule_constraint")}
    </div>
</div>
```

**Auto-update:**

- ĞŸĞ¾Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ğ¾ Ğ¼ĞµÑ€Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°
- Ğ—ĞµĞ»ĞµĞ½Ğ°Ñ Ğ¼ĞµÑ‚ĞºĞ° âœ… Ğ¿Ğ¾ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğ¸
- Evidence Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ hover

---

#### 5.1.4 `components/CallTimer.tsx`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ‚Ğ°Ğ¹Ğ¼ĞµÑ€Ğ° Ğ·Ğ²Ğ¾Ğ½ĞºĞ°

```typescript
interface Props {
    callElapsed: number  // seconds
    stageElapsed: number
    currentStageName: string
}

function CallTimer({ callElapsed, stageElapsed, currentStageName }: Props) {
    const formatTime = (seconds: number) => {
        const mins = Math.floor(seconds / 60)
        const secs = seconds % 60
        return `${mins}:${secs.toString().padStart(2, '0')}`
    }
    
    return (
        <div className="call-timer">
            <div className="total-time">
                â±ï¸ {formatTime(callElapsed)}
            </div>
            <div className="stage-info">
                ğŸ“ {currentStageName}
                <span className="stage-time">
                    ({formatTime(stageElapsed)})
                </span>
            </div>
        </div>
    )
}
```

---

#### 5.1.5 `components/DebugLogPanel.tsx`

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ debug Ğ»Ğ¾Ğ³Ğ¾Ğ² LLM Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹

**Props:**

```typescript
interface DebugLogEntry {
    timestamp: string
    type: string  // "checklist_check" | "client_field_extracted" | ...
    [key: string]: any
}

interface Props {
    logs: DebugLogEntry[]
}
```

**Rendering:**

```typescript
<div className="debug-log-panel">
    <h3>ğŸ› Debug Log</h3>
    <div className="log-entries">
        {logs.map((log, i) => (
            <div className="log-entry">
                <div className="log-header">
                    <span className="timestamp">{log.timestamp}</span>
                    <span className="type">{log.type}</span>
                </div>
                <pre className="log-details">
                    {JSON.stringify(log, null, 2)}
                </pre>
            </div>
        ))}
    </div>
</div>
```

**Log Types:**

- `checklist_check`: LLM Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿ÑƒĞ½ĞºÑ‚Ğ° Ñ‡ĞµĞºĞ»Ğ¸ÑÑ‚Ğ°
- `client_field_extracted`: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»Ğµ Client Card
- `validation_failed`: Evidence Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
- `stage_detected`: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ğ°Ğ´Ğ¸Ñ

---

### 5.2 Component Hierarchy

```
App_TrialClass.tsx
â”œâ”€â”€ CallTimer
â”œâ”€â”€ SettingsPanel (modal)
â”‚   â””â”€â”€ LanguageSelector
â”œâ”€â”€ StageChecklist
â”‚   â””â”€â”€ ChecklistItem (inline)
â”œâ”€â”€ ClientCard
â”‚   â””â”€â”€ ClientField (inline)
â”œâ”€â”€ DebugLogPanel (collapsible)
â””â”€â”€ YouTubeDebugPanel (modal)
```

---

## 6. ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¸ Ğ”Ğ°Ğ½Ğ½Ñ‹Ñ…

### 6.1 Real-time Recording Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER ACTION: Click "Start Recording"                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. BROWSER: navigator.mediaDevices.getDisplayMedia()        â”‚
â”‚    - User selects Chrome tab                                 â”‚
â”‚    - MUST check "Share audio" âš ï¸                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. MEDIARECORDER: Start recording                           â”‚
â”‚    - Format: audio/webm;codecs=opus                         â”‚
â”‚    - Chunk interval: 3 seconds                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. WEBSOCKET /ingest: Send binary chunks                    â”‚
â”‚    - ingestWs.send(audioBlob)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. BACKEND: AudioBuffer.append(chunk)                       â”‚
â”‚    - Buffer chunks in memory                                â”‚
â”‚    - Trigger transcription on:                              â”‚
â”‚      â€¢ Buffer size >= 5 chunks, OR                          â”‚
â”‚      â€¢ 10 seconds since last transcription                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. TRANSCRIPTION: Faster-Whisper                            â”‚
â”‚    - Combine chunks â†’ .webm file                            â”‚
â”‚    - WhisperModel.transcribe(language="id")                 â”‚
â”‚    - VAD filter removes silence                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. ACCUMULATION: accumulated_transcript += text             â”‚
â”‚    - Keep last 1000 words                                   â”‚
â”‚    - Available for LLM analysis                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Analysis Loop Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BACKGROUND TASK: Every 5 seconds                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CHECK: is_live_recording == True?                        â”‚
â”‚    If False â†’ skip iteration                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GET INCOMPLETE ITEMS:                                    â”‚
â”‚    items_to_check = [item for item in current_stage         â”‚
â”‚                      if not checklist_progress[item.id]]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLM ANALYSIS: For each incomplete item                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ analyzer.check_checklist_item()                     â”‚  â”‚
â”‚    â”‚   â”œâ”€> First LLM call: Check completion              â”‚  â”‚
â”‚    â”‚   â”œâ”€> Hard-coded filters                            â”‚  â”‚
â”‚    â”‚   â””â”€> Second LLM call: Validate evidence            â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚    If completed == True:                                    â”‚
â”‚      checklist_progress[item_id] = True                     â”‚
â”‚      checklist_evidence[item_id] = evidence                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. CLIENT CARD EXTRACTION:                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ analyzer.extract_client_card_fields()               â”‚  â”‚
â”‚    â”‚   â”œâ”€> Single LLM call for all fields               â”‚  â”‚
â”‚    â”‚   â”œâ”€> Filter out existing values                    â”‚  â”‚
â”‚    â”‚   â””â”€> Validate each field's evidence                â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚    For each extracted field:                                â”‚
â”‚      client_card_data[field_id] = {value, evidence, ...}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. BUILD UPDATE MESSAGE:                                    â”‚
â”‚    {                                                        â”‚
â”‚      "type": "update",                                      â”‚
â”‚      "callElapsedSeconds": elapsed,                         â”‚
â”‚      "currentStageId": current_stage_id,                    â”‚
â”‚      "stages": [...],  // with completed status            â”‚
â”‚      "clientCard": {...},  // field values                 â”‚
â”‚      "debugLog": [...]  // LLM decision logs               â”‚
â”‚    }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. BROADCAST: Send to all /coach WebSocket connections     â”‚
â”‚    for ws in coach_connections:                             â”‚
â”‚        await ws.send_json(update)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. FRONTEND UPDATE: React state refresh                    â”‚
â”‚    - StageChecklist: Check completed items                  â”‚
â”‚    - ClientCard: Display new fields                         â”‚
â”‚    - CallTimer: Update elapsed time                         â”‚
â”‚    - DebugLogPanel: Show new logs                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.3 Stage Detection Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRIGGER: Every analysis iteration (5s)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CHECK: Should we detect stage?                          â”‚
â”‚    - Time-based: Every 30 seconds                          â”‚
â”‚    - Context-based: When transcript changes significantly  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GET CONTEXT:                                             â”‚
â”‚    - Recent transcript (last 2000 chars)                    â”‚
â”‚    - Current call elapsed time                              â”‚
â”‚    - Previous stage ID                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. DETECT STAGE:                                            â”‚
â”‚    detect_stage_by_context()                                â”‚
â”‚      â”œâ”€> Guard: Transcript too short? â†’ Use first stage    â”‚
â”‚      â”œâ”€> LLM analysis of conversation topics               â”‚
â”‚      â”œâ”€> Confidence check (>= 0.6)                         â”‚
â”‚      â””â”€> Fallback: Time-based detection                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. UPDATE STAGE:                                            â”‚
â”‚    if new_stage_id != current_stage_id:                     â”‚
â”‚        current_stage_id = new_stage_id                      â”‚
â”‚        stage_start_time = time.time()                       â”‚
â”‚        # Mark stage as "current" in UI                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. AI/LLM Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ

### 7.1 Model Selection

**Current Model:** `google/gemini-2.5-flash-preview-09-2025`

**Reasoning:**

| ĞšÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¹ | ĞÑ†ĞµĞ½ĞºĞ° | ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹ |
|----------|--------|-------------|
| **Cost** | â­â­â­â­â­ | $0.10 / 1M input tokens |
| **Speed** | â­â­â­â­â­ | Fastest Gemini model |
| **Quality** | â­â­â­â­ | Good for structured tasks |
| **Indonesian** | â­â­â­â­â­ | Excellent multilingual support |
| **JSON Mode** | â­â­â­â­ | Reliable JSON responses |

**Alternative Models:**

- `anthropic/claude-3.5-sonnet` â€” Better quality, but 50x more expensive
- `meta-llama/llama-3.1-8b-instruct` â€” Cheaper, but worse Indonesian support
- `openai/gpt-4o-mini` â€” Good alternative, slightly more expensive

### 7.2 Prompt Engineering Strategies

#### 7.2.1 Type-Specific Instructions

```python
if item_type == "discuss":
    type_check = """
    This means you must find:
    âœ… A QUESTION being asked, OR
    âœ… An ANSWER that proves the question was asked
    
    BAD examples:
    - "Anak suka belajar" âœ— (no question)
    - "Nanti kita diskusi" âœ— (promise, not actual discussion)
    """
else:  # "say"
    type_check = """
    This means you must find:
    âœ… The manager STATING or EXPLAINING something
    
    BAD examples:
    - "Mau tau cara kerja?" âœ— (asking, not explaining)
    - "Nanti saya jelaskan" âœ— (promise to explain)
    """
```

#### 7.2.2 Anti-Hallucination Rules

```python
prompt += """
CRITICAL VALIDATION RULES:
1. Evidence must be a DIRECT QUOTE from conversation
2. Evidence must CLEARLY AND OBVIOUSLY show action was done
3. Generic phrases like "oke", "baik" are NEVER valid evidence
4. Greetings are NEVER valid evidence
5. Promises to do something are NOT completion
6. If you're even 20% unsure â†’ mark completed=false

BE EXTREMELY CONSERVATIVE. When in doubt, mark as NOT completed.
"""
```

#### 7.2.3 Confidence Guidelines

```python
prompt += """
CONFIDENCE GUIDELINES:
- 90-100%: Action CLEARLY done, evidence is perfect
- 70-89%: Likely done, evidence is good but not perfect
- 50-69%: Possibly done, evidence is weak
- <50%: Probably not done or no evidence
"""
```

#### 7.2.4 Few-Shot Examples

```python
prompt += """
EXAMPLES:

âœ… GOOD:
Action: "Ask about child's age"
Evidence: "Anaknya berapa tahun?"
Reasoning: Direct question about age

âœ… GOOD:
Action: "Identify parent concerns"
Evidence: "Papa khawatir anak kurang fokus"
Reasoning: Clearly states a concern

âŒ BAD:
Action: "Ask about child's age"
Evidence: "Oke, selamat datang"
Reasoning: Just a greeting, no connection to age

âŒ BAD:
Action: "Explain curriculum"
Evidence: "Mau tau kurikulum kami?"
Reasoning: Asking, not explaining
"""
```

### 7.3 Error Handling & Retries

```python
try:
    response = self._call_llm(prompt)
    result = json.loads(response)
except requests.exceptions.Timeout:
    print("âš ï¸ LLM timeout, skipping this check")
    return False, 0.0, "Timeout", {}
except requests.exceptions.RequestException as e:
    print(f"âš ï¸ LLM API error: {e}")
    return False, 0.0, str(e), {}
except json.JSONDecodeError:
    print("âš ï¸ LLM returned invalid JSON")
    # Try to extract JSON from markdown
    if "```json" in response:
        content = response.split("```json")[1].split("```")[0].strip()
        result = json.loads(content)
    else:
        return False, 0.0, "Invalid JSON", {}
```

### 7.4 Cost Optimization

**Current Usage:**

- **Checklist checks:** ~5-10 LLM calls per analysis cycle (5s)
  - First pass: ~200 tokens per check
  - Validation pass: ~150 tokens per validation
  
- **Client card extraction:** 1 LLM call per analysis cycle
  - ~800 tokens per call

**Estimated Cost per Hour:**

```
Checklist: 10 calls/cycle Ã— 12 cycles/min Ã— 60 min Ã— 350 tokens = 2.52M tokens
Client Card: 1 call/cycle Ã— 12 cycles/min Ã— 60 min Ã— 800 tokens = 0.58M tokens

Total: ~3.1M tokens/hour Ã— $0.10/1M = $0.31/hour
```

**Optimization Strategies:**

1. âœ… **Use Gemini Flash** instead of Claude (50x cheaper)
2. âœ… **Check only incomplete items** (not rechecking completed ones)
3. âœ… **Skip client card if no new transcript** (context length check)
4. â³ **Batch multiple items in single call** (future improvement)
5. â³ **Increase analysis interval** to 10s instead of 5s (future improvement)

---

## 8. Deployment

### 8.1 Backend (Railway)

**Platform:** Railway (https://railway.app)

**Configuration File:** `railway.toml`

```toml
[build]
builder = "nixpacks"

[deploy]
startCommand = "uvicorn backend.main_trial_class:app --host 0.0.0.0 --port $PORT"
healthcheckPath = "/health"
healthcheckTimeout = 100
restartPolicyType = "ON_FAILURE"
restartPolicyMaxRetries = 3
```

**Environment Variables:**

```bash
OPENROUTER_API_KEY=sk-or-v1-...
PORT=8000  # Auto-set by Railway
```

**Build Process:**

1. Railway detects Python project
2. Installs dependencies from `requirements.txt`
3. Downloads Whisper model (`base`) on first run
4. Starts Uvicorn server
5. Health check at `/health`

**Domain:**

- Production: `https://salesbestfriend-production.up.railway.app`
- WebSocket: `wss://salesbestfriend-production.up.railway.app`

**Monitoring:**

- Railway Dashboard: Logs, metrics, deployments
- Health endpoint: `GET /health` returns:
  ```json
  {
    "status": "healthy",
    "coach_connections": 1,
    "is_recording": true
  }
  ```

---

### 8.2 Frontend (Vercel)

**Platform:** Vercel (https://vercel.com)

**Configuration File:** `vercel.json`

```json
{
  "buildCommand": "cd frontend && npm run build",
  "outputDirectory": "frontend/dist",
  "framework": "vite"
}
```

**Environment Variables:**

```bash
# Set in Vercel dashboard under Settings â†’ Environment Variables
VITE_API_WS=wss://salesbestfriend-production.up.railway.app
```

**Build Process:**

1. Vercel detects Vite project
2. Runs `npm install` in `frontend/`
3. Runs `npm run build` (TypeScript compilation + Vite build)
4. Deploys `dist/` folder to edge network
5. Automatic HTTPS + CDN

**Domain:**

- Production: Assigned by Vercel (e.g., `salesbestfriend-xxx.vercel.app`)
- Custom domain: Can be configured in Vercel settings

**Automatic Deployments:**

- **Main branch** â†’ Production deployment
- **Pull requests** â†’ Preview deployments
- **Rollback** available in Vercel dashboard

---

### 8.3 Deployment Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DEVELOPER: Push to GitHub                                â”‚
â”‚    git push origin main                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RAILWAY       â”‚    â”‚ 2. VERCEL        â”‚
â”‚ (Backend)        â”‚    â”‚ (Frontend)       â”‚
â”‚                  â”‚    â”‚                  â”‚
â”‚ - Detect change  â”‚    â”‚ - Detect change  â”‚
â”‚ - Build image    â”‚    â”‚ - npm install    â”‚
â”‚ - Run tests      â”‚    â”‚ - npm run build  â”‚
â”‚ - Deploy         â”‚    â”‚ - Deploy to CDN  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. HEALTH CHECK  â”‚    â”‚ 3. SMOKE TEST    â”‚
â”‚ GET /health      â”‚    â”‚ Load homepage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. PRODUCTION LIVE âœ…                                       â”‚
â”‚ - Frontend: https://salesbestfriend.vercel.app              â”‚
â”‚ - Backend: https://salesbestfriend-production.up.railway.appâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 8.4 Rollback Procedure

**If production breaks:**

1. **Railway:**
   - Go to Railway dashboard
   - Click on deployment history
   - Click "Redeploy" on last working version
   
2. **Vercel:**
   - Go to Vercel dashboard â†’ Deployments
   - Find last working deployment
   - Click "Promote to Production"

3. **GitHub:**
   - Revert commit: `git revert <commit-hash>`
   - Push: `git push origin main`
   - Wait for auto-redeploy

---

## 9. ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

### 9.1 Environment Variables

#### Backend (`backend/.env`)

```bash
# OpenRouter API Key (REQUIRED)
OPENROUTER_API_KEY=sk-or-v1-...

# Optional: Model override (default: gemini-2.5-flash)
# LLM_MODEL=anthropic/claude-3.5-sonnet

# Optional: Whisper model size (default: base)
# WHISPER_MODEL_SIZE=small

# Optional: Analysis interval (default: 5)
# ANALYSIS_INTERVAL_SECONDS=10

# Optional: Transcription language (default: id)
# TRANSCRIPTION_LANGUAGE=id
```

#### Frontend (`frontend/.env`)

```bash
# Backend WebSocket URL
VITE_API_WS=ws://localhost:8000  # Development
# VITE_API_WS=wss://salesbestfriend-production.up.railway.app  # Production
```

### 9.2 Call Structure Customization

**Location:** `backend/call_structure_config.py`

**How to modify:**

1. Edit `DEFAULT_CALL_STRUCTURE` list
2. Add/remove stages
3. Add/remove items within stages
4. Change timing (`startOffsetSeconds`, `durationSeconds`)

**Example:**

```python
{
    "id": "stage_8_payment",  # New stage
    "name": "Payment Processing",
    "startOffsetSeconds": 2700,  # 45 min
    "durationSeconds": 300,  # 5 min
    "items": [
        {
            "id": "explain_payment_options",
            "type": "say",
            "content": "Explain available payment methods"
        },
        {
            "id": "process_payment",
            "type": "discuss",
            "content": "Process payment or schedule it"
        }
    ]
}
```

### 9.3 Client Card Customization

**Location:** `backend/client_card_config.py`

**How to modify:**

1. Edit `DEFAULT_CLIENT_CARD_FIELDS` list
2. Add/remove fields
3. Update LLM extraction hints in `LLM_EXTRACTION_HINTS`

**Example:**

```python
{
    "id": "child_school",
    "label": "Child's School",
    "hint": "Name of school and type (public/private/homeschool)",
    "multiline": False,
    "category": "child_info"
}

# Add to extraction hints:
LLM_EXTRACTION_HINTS["child_school"] = "Extract school name and type if mentioned"
```

---

## 10. Security & Permissions

### 10.1 API Key Security

**OpenRouter API Key:**

- âœ… Stored in `.env` (not in git)
- âœ… Only accessible by backend
- âœ… Transmitted over HTTPS to OpenRouter
- âš ï¸ **Never exposed to frontend**

**Best Practices:**

1. Rotate keys periodically (monthly)
2. Use separate keys for dev/prod
3. Monitor usage on OpenRouter dashboard
4. Set spending limits in OpenRouter settings

### 10.2 CORS Configuration

**Current Settings:**

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # âš ï¸ Allow all origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)
```

**Production Recommendations:**

```python
# Option 1: Restrict to specific domains
allow_origins=[
    "https://salesbestfriend.vercel.app",
    "http://localhost:3000"  # Dev only
]

# Option 2: Use environment variable
allow_origins=os.getenv("ALLOWED_ORIGINS", "*").split(",")
```

### 10.3 WebSocket Security

**Current State:**

- âŒ No authentication
- âŒ No rate limiting
- âœ… HTTPS/WSS encryption in production

**Production Recommendations:**

1. **Add authentication:**
   ```python
   @app.websocket("/ingest")
   async def websocket_ingest(websocket: WebSocket, token: str):
       if not verify_token(token):
           await websocket.close(code=403)
           return
   ```

2. **Rate limiting:**
   ```python
   from slowapi import Limiter
   limiter = Limiter(key_func=get_remote_address)
   
   @limiter.limit("60/minute")
   @app.websocket("/ingest")
   async def websocket_ingest(...):
       ...
   ```

3. **Connection limits:**
   ```python
   MAX_CONNECTIONS = 10
   if len(coach_connections) >= MAX_CONNECTIONS:
       await websocket.close(code=503)
   ```

### 10.4 Data Privacy

**Current State:**

- âœ… No data persistence (all in memory)
- âœ… Data cleared on server restart
- âœ… No logging of sensitive info
- âŒ No encryption of in-memory data

**If adding persistence:**

1. Encrypt sensitive fields (names, contact info)
2. Comply with GDPR (right to deletion, data export)
3. Add user consent for recording
4. Implement data retention policy

---

## ğŸ“Œ Appendix

### A. Key Files Reference

| File | Purpose | Lines |
|------|---------|-------|
| `backend/main_trial_class.py` | FastAPI server + WebSockets | ~800 |
| `backend/trial_class_analyzer.py` | LLM analysis logic | ~935 |
| `backend/call_structure_config.py` | Call stages config | ~413 |
| `backend/client_card_config.py` | Client card fields config | ~216 |
| `backend/utils/realtime_transcriber.py` | Whisper transcription | ~150 |
| `backend/utils/audio_buffer.py` | Audio buffering | ~50 |
| `frontend/src/App_TrialClass.tsx` | Main React app | ~485 |
| `frontend/src/components/StageChecklist.tsx` | Checklist UI | ~200 |
| `frontend/src/components/ClientCard.tsx` | Client card UI | ~150 |

### B. External Dependencies

**Backend:**

- `fastapi` â€” Web framework
- `uvicorn` â€” ASGI server
- `faster-whisper` â€” Speech-to-text
- `ctranslate2` â€” Whisper inference
- `requests` â€” HTTP client
- `python-dotenv` â€” Env config
- `pydub` â€” Audio processing
- `yt-dlp` â€” YouTube downloader

**Frontend:**

- `react` â€” UI library
- `react-dom` â€” React rendering
- `typescript` â€” Type safety
- `vite` â€” Build tool

### C. Performance Metrics

| Metric | Value | Notes |
|--------|-------|-------|
| **Transcription Latency** | 3-5s | Time from audio chunk to text |
| **LLM Response Time** | 1-3s | Gemini Flash response time |
| **Analysis Cycle** | 5s | How often LLM runs |
| **WebSocket Latency** | <100ms | Frontend â†” Backend |
| **Memory Usage (Backend)** | ~500MB | With Whisper base model loaded |
| **CPU Usage (Backend)** | 20-40% | During active transcription |

### D. Known Limitations

1. **Single user session** â€” No multi-user support
2. **No persistence** â€” All data lost on restart
3. **Indonesian only** â€” Optimized for Indonesian language
4. **Whisper base model** â€” Balance of speed vs accuracy
5. **5s analysis cycle** â€” Not real-time item completion detection
6. **No authentication** â€” Anyone can connect to WebSockets
7. **Memory-only storage** â€” Limited by server RAM

### E. Future Improvements

1. **Multi-user support** â€” Session management per user
2. **Persistent storage** â€” PostgreSQL for call history
3. **Authentication** â€” JWT tokens for WebSocket connections
4. **Batch LLM calls** â€” Check multiple items in single call
5. **Faster analysis cycle** â€” Optimize to 2-3s
6. **Better Whisper model** â€” Medium or Large for accuracy
7. **Multilingual support** â€” English, Spanish, etc.
8. **Export functionality** â€” PDF/CSV export of call data
9. **Analytics dashboard** â€” Call performance metrics
10. **Custom playbooks** â€” User-editable call structures

---

## ğŸ‰ Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ

**SalesBestFriend** â€” ÑÑ‚Ğ¾ production-ready ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ real-time AI-ĞºĞ¾ÑƒÑ‡Ğ¸Ğ½Ğ³Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ğ¾Ğ².

**ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ:**

- âœ… **Real-time transcription** Ñ Whisper
- âœ… **AI-powered analysis** Ñ Gemini 2.5 Flash
- âœ… **Multi-layer validation** Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸
- âœ… **Production deployment** Ğ½Ğ° Railway + Vercel
- âœ… **Indonesian language** Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
- âœ… **Cost-effective** ($0.31/hour)

**Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾ Ğº Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:**

1. ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹
2. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ `.env` Ñ API ĞºĞ»ÑÑ‡Ğ¾Ğ¼
3. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ backend (`uvicorn main:app`)
4. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ frontend (`npm run dev`)
5. ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ trial class Ğ·Ğ²Ğ¾Ğ½Ğ¾Ğº!

---

**Ğ’ĞµÑ€ÑĞ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸:** 2.0  
**ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ:** 24 Ğ½Ğ¾ÑĞ±Ñ€Ñ 2025  
**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** Production Ready âœ…

